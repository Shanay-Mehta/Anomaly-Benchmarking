{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, f1_score, roc_curve,auc\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "RANDOM_SEED = 2021\n",
    "TEST_PCT = 0.3\n",
    "\n",
    "\n",
    "alpha_values = list()\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.beta = tf.Variable(0.1)\n",
    "\n",
    "        self.encoding_dim = 14\n",
    "        self.hidden_dim_1 = int(encoding_dim / 2)  #\n",
    "        self.hidden_dim_2 = 4\n",
    "        self.learning_rate = 1e-7\n",
    "\n",
    "        self.input_layer = tf.keras.layers.Input(shape=(1,))\n",
    "        self.d0 = tf.keras.layers.Dense(encoding_dim, activation=self.prelu,\n",
    "                                        activity_regularizer=tf.keras.regularizers.l2(learning_rate))\n",
    "        self.d1 = tf.keras.layers.Dropout(0.2)\n",
    "        self.d2 = tf.keras.layers.Dense(hidden_dim_1, activation=self.prelu)\n",
    "        self.d3 = tf.keras.layers.Dense(hidden_dim_2, activation=self.prelu)\n",
    "        # Decoder\n",
    "        self.d4 = tf.keras.layers.Dense(hidden_dim_1, activation=self.prelu)\n",
    "        self.d5 = tf.keras.layers.Dropout(0.2)\n",
    "        self.d6 = tf.keras.layers.Dense(encoding_dim, activation=self.prelu)\n",
    "        self.d7 = tf.keras.layers.Dense(input_dim, activation=self.prelu)\n",
    "\n",
    "    def prelu(self, x):\n",
    "        ef=x/(1+np.absolute(x))\n",
    "        return ef * self.beta\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        alpha_values.append(self.beta.numpy())\n",
    "\n",
    "        x = self.d0(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.d5(x)\n",
    "        x = self.d6(x)\n",
    "        x = self.d7(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('yahoo1.csv')\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    X_train = []\n",
    "\n",
    "    normal_data = X[y == 0]\n",
    "    train_threshold = math.floor(0.7 * len(data))\n",
    "\n",
    "    for i in range(train_threshold):\n",
    "        X_train.append(normal_data[i])\n",
    "\n",
    "    nb_epoch = 50\n",
    "    batch_size = 64\n",
    "    input_dim = X.shape[1]  # num of columns, 30\n",
    "    encoding_dim = 14\n",
    "    hidden_dim_1 = int(encoding_dim / 2)  #\n",
    "    hidden_dim_2 = 4\n",
    "    learning_rate = 1e-7\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    encoder = tf.keras.layers.Dense(encoding_dim, activation=\"tanh\",\n",
    "                                    activity_regularizer=tf.keras.regularizers.l2(learning_rate))(input_layer)\n",
    "    encoder = tf.keras.layers.Dropout(0.2)(encoder)\n",
    "    encoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "    encoder = tf.keras.layers.Dense(hidden_dim_2, activation=tf.nn.leaky_relu)(encoder)\n",
    "    # Decoder\n",
    "    decoder = tf.keras.layers.Dense(hidden_dim_1, activation='relu')(encoder)\n",
    "    decoder = tf.keras.layers.Dropout(0.2)(decoder)\n",
    "    decoder = tf.keras.layers.Dense(encoding_dim, activation='relu')(decoder)\n",
    "    decoder = tf.keras.layers.Dense(input_dim, activation='tanh')(decoder)\n",
    "    autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "    autoencoder.summary()\n",
    "    # define our early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True)\n",
    "    modelq10 = MyModel()\n",
    "    modelq10.compile(metrics=['accuracy'],loss='mean_squared_error', optimizer='adam')\n",
    "    X_test = X\n",
    "    X_train = np.array(X_train)\n",
    "    history=modelq10.fit(X_train, X_train,\n",
    "                              epochs=nb_epoch,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(X_test, X_test),\n",
    "                              verbose=1,\n",
    "                              callbacks=[ early_stop]\n",
    "                              ).history\n",
    "\n",
    "    plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "    plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    test_x_predictions = modelq10.predict(X_test)\n",
    "    mse = np.mean(np.power(X_test - test_x_predictions, 2), axis=1)\n",
    "    print('mse',mse)\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1)\n",
    "    ax1.set_title('comparison')\n",
    "    ax1.set_xlabel('time')\n",
    "    ax1.set_ylabel('mse')\n",
    "    ax1.plot(mse, label=\"dataset\")\n",
    "\n",
    "    ax2.set_xlabel('time')\n",
    "    ax2.set_ylabel('value')\n",
    "    ax2.plot(X_test, label=\"test_data\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    mean_mse=np.mean(mse)\n",
    "    std_mse=np.std(mse)\n",
    "    lper = np.percentile(mse, 5)\n",
    "    uper = np.percentile(mse, 95)\n",
    "    print('lper', lper)\n",
    "    print('uper', uper)\n",
    "    y_pred = mse.copy()\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    count = 0\n",
    "    for itr in range(len(y_pred)):\n",
    "        if (mse[itr] <= lper or mse[itr] >= uper):\n",
    "            count = count + 1\n",
    "            y_pred[itr]=1\n",
    "        else:\n",
    "            y_pred[itr]=0\n",
    "\n",
    "    precision_auto = precision_score(y, y_pred)\n",
    "    recall_auto = recall_score(y, y_pred)\n",
    "    f1_score_auto = f1_score(y, y_pred)\n",
    "    fpr8, tpr8, thresholds = roc_curve(y, y_pred)\n",
    "    auc_roc_auto = auc(fpr8, tpr8)\n",
    "\n",
    "\n",
    "    print(\"Precision: {:.4f}\".format(precision_auto))\n",
    "    print(\"Recall: {:.4f}\".format(recall_auto))\n",
    "    print(\"F1-score: {:.4f}\".format(f1_score_auto))\n",
    "    print(\"AUC-ROC: {:.4f}\".format(auc_roc_auto))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
