{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import math\n",
    "RANDOM_SEED = 2021\n",
    "TEST_PCT = 0.3\n",
    "\n",
    "# Function to split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "alpha_values = list()\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.beta = tf.Variable(0.1)\n",
    "        self.lstm_units = 14\n",
    "        self.input_layer = tf.keras.layers.Input(shape=(3, 1))\n",
    "        self.d0 = tf.keras.layers.LSTM(units=14, activation=self.prelu, return_sequences=True)\n",
    "        self.d1 = tf.keras.layers.Dropout(0.2)\n",
    "        self.d2 = tf.keras.layers.LSTM(units=8, activation=self.prelu)\n",
    "        self.d3 = tf.keras.layers.Dense(1, activation=self.prelu)\n",
    "\n",
    "    def prelu(self, x):\n",
    "        ef=x/(1+np.absolute(x))\n",
    "        return ef * self.beta\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        alpha_values.append(self.beta.numpy())\n",
    "        x = tf.expand_dims(x, axis=-1)  # Add an extra dimension for time_steps\n",
    "        x = self.d0(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('yahoo3.csv')\n",
    "    X_data = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    scaler = StandardScaler()\n",
    "    X_data = scaler.fit_transform(X_data)\n",
    "\n",
    "    # Choose the number of time steps\n",
    "    n_steps = 3\n",
    "\n",
    "    train_threshold = math.floor(0.7 * len(data))\n",
    "    X_train, y_train = split_sequence(X_data[:train_threshold][y[:train_threshold] == 0], n_steps)\n",
    "    X_train = np.squeeze(X_train, axis=-1)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    X_test, y_test = split_sequence(X_data, n_steps)\n",
    "    print(X_test.shape)\n",
    "    X_test = np.squeeze(X_test, axis=-1)\n",
    "    nb_epoch = 50\n",
    "    batch_size = 64\n",
    "    input_dim = X_train.shape[1]  # Adjusted to the number of features after splitting\n",
    "    input_layer = tf.keras.layers.Input(shape=(input_dim,))\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode='min',\n",
    "        restore_best_weights=True)\n",
    "    modelq10 = MyModel()\n",
    "    modelq10.compile(metrics=['accuracy'],loss='mean_squared_error', optimizer='adam')\n",
    "    X_train = np.array(X_train)\n",
    "    history=modelq10.fit(X_train, y_train,\n",
    "                              epochs=nb_epoch,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              verbose=1,\n",
    "                              callbacks=[ early_stop]\n",
    "                              ).history\n",
    "    plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    print(X_test.shape)\n",
    "    test_x_predictions = modelq10.predict(X_test)\n",
    "    mse = np.mean(np.power(X_test - test_x_predictions, 2), axis=1)\n",
    "    print('mse',mse)\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1)\n",
    "    ax1.set_title('comparison')\n",
    "    ax1.set_xlabel('time')\n",
    "    ax1.set_ylabel('mse')\n",
    "    ax1.plot(mse, label=\"dataset\")\n",
    "\n",
    "    ax2.set_xlabel('time')\n",
    "    ax2.set_ylabel('value')\n",
    "    ax2.plot(X_test, label=\"test_data\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    mean_mse=np.mean(mse)\n",
    "    std_mse=np.std(mse)\n",
    "    lper = np.percentile(mse, 5)\n",
    "    uper = np.percentile(mse, 95)\n",
    "    print('lper', lper)\n",
    "    print('uper', uper)\n",
    "    y_pred = mse.copy()\n",
    "    y_pred = np.array(y_pred)\n",
    "    print(y_pred.shape)\n",
    "    # Thresholding based on the score\n",
    "    count = 0\n",
    "    for itr in range(len(y_pred)):\n",
    "        if (mse[itr] <= lper or mse[itr] >= uper):\n",
    "            count = count + 1\n",
    "            y_pred[itr]=1\n",
    "        else:\n",
    "            y_pred[itr]=0\n",
    "\n",
    "    y=y[3:]\n",
    "    precision_auto = precision_score(y, y_pred)\n",
    "    recall_auto = recall_score(y, y_pred)\n",
    "    f1_score_auto = f1_score(y, y_pred)\n",
    "    fpr8, tpr8, thresholds = roc_curve(y, y_pred)\n",
    "    auc_roc_auto = auc(fpr8, tpr8)\n",
    "\n",
    "\n",
    "    print(\"Precision: {:.4f}\".format(precision_auto))\n",
    "    print(\"Recall: {:.4f}\".format(recall_auto))\n",
    "    print(\"F1-score: {:.4f}\".format(f1_score_auto))\n",
    "    print(\"AUC-ROC: {:.4f}\".format(auc_roc_auto))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
